# System Architecture: HyDE-Powered SQL Generation

This document provides a detailed technical overview of the SQL generation system. The architecture is designed to convert natural language questions into accurate SQL queries by leveraging a combination of schema vectorization, hypothetical document embeddings (HyDE), and large language models (LLMs).

## Core Components

The system is composed of four main components:

1.  **Orchestration Script (`run_deepseek.ps1`)**: A PowerShell script that initializes the configuration and orchestrates the execution of the other components.
2.  **Schema Vectorization (`schema_vectorization_module.py`)**: A Python module responsible for converting the database schema into a searchable vector representation.
3.  **Focused Schema Generation (`hyde_module.py`)**: A Python module that implements the HyDE technique to identify the most relevant parts of the schema for a given question.
4.  **SQL Generation (`deepseek_sql_generator_finalV5.py`)**: The main Python script that integrates the other components to generate the final SQL query.

## Detailed Workflow

The SQL generation process follows a sequential workflow, with each component playing a critical role in refining the information needed for the final query.

### 1. Orchestration and Configuration

The process begins with the `run_deepseek.ps1` script, which performs the following actions:

-   **Configuration**: Sets up critical parameters, including the API key, model endpoint, database connection details, and input/output paths.
-   **Schema Graph Generation**: Executes `create_schema_graphs.py` to analyze the database schema and generate a graph representation of table relationships. This graph is used to determine the most efficient JOIN paths between tables.
-   **Execution**: Invokes the main `deepseek_sql_generator_finalV5.py` script to initiate the SQL generation process.

### 2. Schema Vectorization

Before the main workflow begins, the `SchemaVectorizer` module processes the database schema to make it searchable. This is a one-time setup process per database.

-   **Schema Extraction**: The module connects to the database (either SQLite or PostgreSQL) and extracts detailed schema information, including table names, column names, data types, and constraints.
-   **Embedding Generation**: The extracted schema descriptions are fed into a sentence transformer model (`all-MiniLM-L6-v2`) to generate vector embeddings for each description.
-   **Vector Storage**: The embeddings are stored in a LanceDB vector database, creating a searchable representation of the schema. This allows for efficient similarity searches to find relevant schema parts.

### 3. Focused Schema Generation (HyDE)

The `HydeModule` is responsible for narrowing down the schema to only the most relevant parts for a given question.

-   **Hypothetical Document Generation**: The module takes the user's natural language question and uses the DeepSeek model to generate a "hypothetical document"â€”a descriptive answer that outlines the ideal data needed to answer the question.
-   **Query Embedding**: The hypothetical document is converted into a vector embedding using the same sentence transformer model.
-   **Schema Search**: The embedding is used to perform a similarity search on the LanceDB vector database. The search retrieves the most relevant schema descriptions.
-   **Focused Schema Construction**: The retrieved descriptions are combined to create a "focused schema," which is a concise representation of the schema containing only the tables and columns relevant to the question.

### 4. SQL Generation

The `deepseek_sql_generator_finalV5.py` script integrates all the components to generate the final SQL query.

-   **Prompt Construction**: The script constructs a detailed prompt for the DeepSeek model, which includes:
    -   The focused schema generated by the `HydeModule`.
    -   Sample data from the relevant tables.
    -   The deterministic JOIN clauses derived from the schema graph.
    -   The user's natural language question.
-   **LLM Invocation**: The prompt is sent to the DeepSeek model, which generates the SQL query based on the provided context.
-   **Enhanced Feedback Loop with HyDE**: The system executes the generated query against the database and implements a sophisticated retry mechanism:
    -   **Error Detection**: The system detects both invalid SQL responses (e.g., "I cannot generate...") and execution errors from the database.
    -   **HyDE-Based Regeneration**: When a SQL query fails execution, the system:
        1. Passes the failed SQL, natural language question, and error message to the HyDE module.
        2. Generates a new hypothetical document focused specifically on addressing the error.
        3. Creates a new focused schema based on this error-aware hypothetical document.
        4. Generates a new SQL query using the improved schema.
    -   **Multiple Attempts**: The system allows up to 5 retry attempts, with each attempt leveraging the error information from previous attempts.
    -   **Comprehensive Logging**: Each retry attempt is logged, including the original SQL, error message, and the new focused schema.
    -   **Technical Implementation**: 
        1. The `get_focused_schema_with_error` method in the HyDE module takes the error message into account when generating a new focused schema.
        2. The `sql_feedback_loop` function orchestrates the retry process, using HyDE for regeneration after failures.
        3. The `execute_sql_query` function executes queries against the database to catch actual execution errors.

## Conclusion

This architecture provides a robust and efficient solution for converting natural language questions into accurate SQL queries. By combining schema vectorization, hypothetical document embeddings, and a feedback loop, the system can intelligently identify the most relevant parts of the database schema and generate high-quality queries that are more likely to be correct on the first attempt.
